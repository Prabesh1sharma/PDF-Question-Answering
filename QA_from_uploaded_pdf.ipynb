{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prabeshsharma/Documents/QA_From_uploaded_pdf/env/lib/python3.12/site-packages/weaviate/__init__.py:144: DeprecationWarning: Dep010: Importing AuthApiKey from weaviate is deprecated. Import AuthApiKey from its module: weaviate.auth\n",
      "  _Warnings.root_module_import(name, map_[name])\n",
      "/var/folders/lv/cmxrpk6x201g31179k2jw81w0000gn/T/ipykernel_2344/2120763738.py:7: DeprecationWarning: \n",
      "Python client v3 `weaviate.Client(...)` connections and methods are deprecated and will\n",
      "            be removed by 2024-11-30.\n",
      "\n",
      "            Upgrade your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "                - For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "                - For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "\n",
      "            If you have to use v3 code, install the v3 client and pin the v3 dependency in your requirements file: `weaviate-client>=3.26.7;<4.0.0`\n",
      "  client = weaviate.Client(\n",
      "/Users/prabeshsharma/Documents/QA_From_uploaded_pdf/env/lib/python3.12/site-packages/weaviate/warnings.py:186: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated and will\n",
      "            be removed by 2024-11-30.\n",
      "\n",
      "            Upgrade your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "                - For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "                - For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "\n",
      "            If you have to use v3 code, install the v3 client and pin the v3 dependency in your requirements file: `weaviate-client>=3.26.7;<4.0.0`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Weaviate\n",
    "import weaviate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "WEAVIATE_API = os.getenv(\"WEAVIATE_API\")\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url=WEAVIATE_URL,\n",
    "    auth_client_secret=weaviate.AuthApiKey(api_key=WEAVIATE_API))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixinf unicode error in google colab\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prabeshsharma/Documents/QA_From_uploaded_pdf/env/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Specify embedding model (Using huggingface sentence transformer)\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "#model_kwargs = {\"device\":\"cuda\"}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    #model_kwargs = model_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key = os.getenv(\"GROQ_API_KEY\"),\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 20)\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template=\"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use ten sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def qafrompdf(pdf_directory,question):\n",
    "#     loader = PyPDFLoader(pdf_directory,extract_images = True)\n",
    "#     pages = loader.load()\n",
    "    \n",
    "#     docs = text_splitter.split_documents(pages)\n",
    "#     vector_db = Weaviate.from_documents(\n",
    "#     docs, embeddings, client = client, by_text=False)\n",
    "#     output_parser=StrOutputParser()\n",
    "#     retriever=vector_db.as_retriever()\n",
    "#     rag_chain = (\n",
    "#     {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | output_parser\n",
    "# )\n",
    "#     ans = rag_chain.invoke(question)\n",
    "#     return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from cachetools import TTLCache\n",
    "import nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply nest_asyncio to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize the cache (stores 100 answers for up to 10 minutes)\n",
    "cache = TTLCache(maxsize=100, ttl=600)\n",
    "\n",
    "async def process_pdf_async(pdf_directory):\n",
    "    loader = PyPDFLoader(pdf_directory, extract_images=True)\n",
    "    pages = loader.load()\n",
    "    \n",
    "    # Split documents efficiently\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "    \n",
    "    # Insert documents into the vector DB asynchronously\n",
    "    vector_db = Weaviate.from_documents(\n",
    "        docs, embeddings, client=client, by_text=False\n",
    "    )\n",
    "    \n",
    "    return vector_db\n",
    "\n",
    "async def qafrompdf_async(pdf_directory, question):\n",
    "    # Check if the question is in cache\n",
    "    if question in cache:\n",
    "        return cache[question]\n",
    "\n",
    "    # Process the PDF asynchronously\n",
    "    vector_db = await process_pdf_async(pdf_directory)\n",
    "\n",
    "    # Set up retrieval and RAG chain\n",
    "    retriever = vector_db.as_retriever()\n",
    "    output_parser = StrOutputParser()\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | output_parser\n",
    "    )\n",
    "    \n",
    "    # Get the answer\n",
    "    ans = rag_chain.invoke(question)\n",
    "    \n",
    "    # Store the answer in cache\n",
    "    cache[question] = ans\n",
    "    \n",
    "    return ans\n",
    "\n",
    "# Wrapper function for interactive environments\n",
    "async def main(pdf_directory, question):\n",
    "    return await qafrompdf_async(pdf_directory, question)\n",
    "\n",
    "# Call this function in your interactive environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ant Colony Optimization (ACO) is a bio-inspired optimization technique based on the foraging behavior of ants. It simulates the behavior of ants searching for optimal paths in a network to solve complex routing problems. ACO uses artificial \"ants\" as agents that move through the network, depositing pheromone on the paths they traverse. The intensity of the pheromone represents the quality or desirability of the path. Ants are attracted to paths with stronger pheromone concentrations, but they also explore new paths. The algorithm balances exploration and exploitation to find optimal solutions. ACO can be used for dynamic routing optimization, adapting to changing conditions such as traffic updates and new orders. It is a metaheuristic algorithm that can be used to find approximate solutions to complex problems.\n"
     ]
    }
   ],
   "source": [
    "pdf = \"/Users/prabeshsharma/Downloads/Prabesh_24_oct_9_(Dynamic Routie Optimization research).pdf\"\n",
    "question = \"what is Ant colony optimization\"\n",
    "result = await main(pdf, question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
